---
title: "Weight Lifting Exercise Dataset -- Exploratory Analyisis"
author: "You-Cyuan Jhang"
date: "June 17, 2014"
output: html_document
---

## Setup

Load required libraries. Use data.table for faster data cleanup.

```{r load_library}
library(caret, quietly = T)
library(data.table)
cwd <- "~/Dropbox/Course/2014/Coursera_Practical_Machine_Learning/weight_lifting"
```

## Data Cleanup

First, read the weight lifting dataset. The dataset **pml-training.csv** will be use to build machine learning model. We will then use the model to predict testing dataset given in **pml-testing.csv**. So, my exploratory analysis will focus on training dataset only.

```{r read_data}
wle_data <- fread(paste0(cwd, "/data/original/pml-training.csv"), na.strings=c("NA","#DIV/0!",""))
# wl_submission <- read.csv(paste0(cwd, "/data/original/pml-testing.csv"))
```

First, according to the [paper](http://groupware.les.inf.puc-rio.br/public/papers/2013.Velloso.QAR-WLE.pdf), they use a sliding window approach to detect and separate each movement. Then the statics (mean, variance, skiness..) of this windos measure is calculated and stored. Therefore, my first step is to filter out this record from the original dataset. Then remove unrevelent **time stamp** columns, **record_id** column and **new_window** column.

```{r window}
wle_data <- wle_data[new_window == "yes",]
wle_data <- wle_data[, c("V1", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window") := NULL]
```

Notice that some of the columns has value **#DIV/0!** from the original dataset. This is because when computing the statictics in these columns, some of the value are missing or zero. I alreadt replace these values with **NA** when reading data.
Now I will use imputation method in **caret** package to fill these missing values. Also remove nearzero columns using **nearZeroVar()** function in caret.

```{r preprocess}
# Convert should be numeric columns to numeric
wle_data <- wle_data[,lapply(.SD, as.numeric), by=c("num_window", "user_name", "classe")]
# Detect near zero columns and remove them
wle_nearzero <- nearZeroVar(wle_data, saveMetrics = TRUE)
wle_numeric <- wle_data[,!wle_nearzero$nzv, with = FALSE]
wle_numeric <- wle_numeric[,4:ncol(wle_numeric), with = FALSE]
# Impute missing values using knn with k = 5
impute_model <- preProcess(wle_numeric, method = "knnImpute", k = 5)
wle_data_clean <- predict(impute_model, newdata = wle_numeric)
classe <- wle_data$classe
```

## Plot
It's impossible to look at all of the feature paris plots, since we have ~140 features. Here I only look at a few interesting cases. This is just to draw myslef the attention that some of variables are correlated. 
```{r plots}
# Get all arm names
# arm_colnames <- grep("_arm", colnames(wle_data_clean), value = TRUE)
# forearm_colnames <- grep("_forearm", colnames(wle_data_clean), value = TRUE)
# belt_colnames <- grep("_belt", colnames(wle_data_clean), value = TRUE)
# dumbbell_colnames <- grep("_dumbbell", colnames(wle_data_clean), value = TRUE)
qplot(wle_data_clean$amplitude_pitch_forearm, wle_data_clean$amplitude_roll_forearm, color = classe)
qplot(wle_data_clean$avg_pitch_forearm, wle_data_clean$avg_pitch_arm, color = classe)
qplot(classe, wle_data_clean$avg_roll_forearm, color = classe, geom = c("boxplot", "jitter"))
```

## Principle Component Analysis

Since the dataset has ~140 features and some of the fearutes are correlated, one way to perform dimentional reduction is to use principle component analysis.
```{r pca}
wle_data_pca_model <- preProcess(wle_data_clean, method = c("center", "scale", "pca"), thresh = 0.9)
wle_data_pca <- predict(wle_data_pca_model, newdata = wle_data_clean)
wle_data_pca_model$numComp
```

With threshold 0.9, which means 90% of variance can be explained by the first `r wle_data_pca_model$numComp` principle components! Plot the first three pairs of principle components.

```{r pca_plot}
qplot(classe, PC1, data = wle_data_pca, color = classe, geom = c("boxplot", "jitter"))
qplot(classe, PC2, data = wle_data_pca, color = classe, geom = c("boxplot", "jitter"))
qplot(classe, PC3, data = wle_data_pca, color = classe, geom = c("boxplot", "jitter"))
```

## BoxCox Transformation

```{r boxcox}
wle_data_boxcox_model <- preProcess(wle_data_clean, method = c("BoxCox"))
wle_data_boxcox <- predict(wle_data_boxcox_model, newdata = wle_data_clean)
qplot(classe, wle_data_boxcox$avg_roll_forearm, color = classe, geom = c("boxplot", "jitter"))

```
Does not change the data a lot...

I will use these `r wle_data_pca_model$numComp` principle component as my features  to build machine learning model.
